\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2022


\PassOptionsToPackage{numbers}{natbib}
\usepackage[preprint]{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2022}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2022}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2022}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{placeins}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{multirow}
\usepackage{graphicx}



\title{STUDY: Socially Aware Temporally Casual Decoder Recommender Systems. }




\author{%
 Eltayeb Ahmed \\
  Google Research\\
  \texttt{ekahmed@google.com} \\
\And
  Diana Mincu \\
  Google Research \\
  \texttt{dmincu@google.com} \\
\And
  Lauren Harrell\\
  Google Research \\
  \texttt{laurenharrell@google.com} \\
\And
  Katherine Heller \\
  Google Research \\
  \texttt{kheller@google.com} \\
\
\And
    Subhrajit Roy \\
  Google Research \\
  \texttt{subhrajitroy@google.com} \\
}


\begin{document}


\maketitle
%\vspace{-1em}
\begin{abstract}
With the overwhelming amount of data available both on and offline today, recommender systems have become much needed to help users find items tailored to their interests. 
When social network information exists there are methods that utilize this information to make better recommendations, however the methods are often clunky with complex architectures and training procedures. Furthermore many of the existing methods utilize graph neural networks which are notoriously difficult to train. To address this, we propose Socially-aware Temporally caUsal Decoder recommender sYstems (STUDY). STUDY does joint inference over groups of users who are adjacent in the social network graph using a single forward pass of a modified transformer decoder network. We test our method in a school-based educational content setting, using classroom structure to define social networks.  Our method outperforms both social and sequential methods while maintaining the design simplicity of a single homogeneous network that models all interactions in the data. We also carry out ablation studies to understand the drivers of our performance gains and find that our model depends on leveraging a social network structure that effectively models the similarities in user behavior.

\end{abstract}

\section{Introduction}
Recommender systems are one of the major applications of AI systems and they are an essential driver of many of our online experiences today. With applications ranging from e-commerce~\cite{Li2020HierarchicalBG} and advertising platforms~\cite{liu2021neural} to video platforms~\cite{Deldjoo2020} we are relying on recommender systems to surface relevant and interesting content to individual users. 
In this work we focus on recommender systems deployed in the educational setting~\cite{abdi2020complementing}. In these settings systems can be targeted towards either teachers~\cite{dhahri2021review} or students~\cite{bodily2017review} and in both cases the goal of these systems is to surface relevant and engaging educational material that is beneficial to the students' learning.

A student-facing educational recommender system is built from data relevant to students interaction with the platform, which falls into the following categories~\cite{fang2020deep}:
\begin{itemize}
    \item data about the students which is known as user data
    \item data about the content to be recommended which is known as item data
    \item and data about the context of the current session (e.g. time of day, session device, etc.) which is known as context data
\end{itemize}

Recommender systems are either batch recommender systems that operate on representations of previous interactions that don't model time or relative order, such as collaborative filtering based methods~\cite{su2009survey} and Embarrassingly Shallow Autoenconders (EASE)~\cite{steck2019embarrassingly}; or they can be sequential recommender~\cite{quadrana2018sequence} systems that operate on representations of historical user interaction as sequences~\cite{wang2021survey}.

One of the aspects of doing recommendations in the classroom setting is availability of a clearly-defined hierarchical social network grouping students into classrooms, year groups and schools. This makes the utilization of social recommendation systems~\cite{xia2023disentangled} particularly attractive. Such social recommender systems leverage the relationships between users to make recommendations.

In this work we present Socially-aware Temporally casUal Decoder recommender sYstems (STUDY), a sequence-based recommender system for educational content that makes use of known student hierarchies to improve recommendations. Our method does joint inference over groups of students who are adjacent in the social network. Our method utilizes a single transformer decoder network to model both within-user and cross-user interactions. The current work is organized as follows: we provide a review of the related work in Section~\ref{sec:related}, our problem statement in Section~\ref{section:problem}, an overview of the data and algorithms we conducted our experiments on in Section~\ref{sec:methods} and we present our experimental results in Section~\ref{section:results}.

To sum up, in this paper we:
\begin{itemize}
    \item Propose a novel architecture and data pipeline for doing socially-aware sequential recommendation.
    \item Compare our method against modern and classical recommendation baselines.
    \item Perform ablations and performance breakdowns to better understand our model.
\end{itemize}
 
\newcommand\MultiplierIndivdual{166.33}
\newcommand\MultiplierIntermediate{165.1}
\newcommand\MultiplierKey{17}
\newcommand\MultiplierScale{0.0019\linewidth}
\begin{figure}
    \centering
    \begin{subfigure}[t]{0.31602\linewidth}
        %\vspace{0.35em}
        \includegraphics[width=\linewidth]{figures/main/individual.pdf}
        %\vspace{4.15em}
        \caption{Processing students individually}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.3136\linewidth}
        \includegraphics[width=\linewidth]{figures/main/intermediate.pdf}
        \caption{Equivalent reformulation of individual processing}
    \end{subfigure}
    \hfill
       \begin{subfigure}[t]{0.3136\linewidth}
        \includegraphics[width=\linewidth]{figures/main/study.pdf}
        \caption{Processing students jointly}
    \end{subfigure}
    
    \begin{subfigure}[t]{0.0323\linewidth}
     \vspace{2em}
     % \hspace{7em}
      \includegraphics[width=\linewidth]{figures/main/key.pdf}
    \end{subfigure}
    \caption{In (a) we show a sequential autoregressive transformer with causal attention that processes each user individually, in (b) we show an equivalent joint forward pass that results in the same computation as (a), and finally in (c) we show that by introducing new nonzero values (shown in purple) to the attention mask we allow information to flow across users. We do this by allowing a prediction to condition on all interactions with an earlier timestamp, irrespective of whether the interaction came from the same user or not.}
    \label{figure:main}
\end{figure}


\section{Related Work}
\label{sec:related}
\subsection{Click-through Rate Prediction}
One of the popular approaches for recommender systems is click-through rate prediction~\cite{zhang2021deep}, where we attempt to model the probability of a user clicking on a specific item presented to them. These probabilities are then used as a proxy for what we believe the users preferences are. Click-through Rate (CTR) models typically make predictions for a suggested next item for a user based on the user's sequence of previous interactions, user data and context data. Model architectures used in this problem range from standard models like Transformers used in Behavior Sequence Transformers (BST)~\cite{chen2019behavior} and Convolutional Neural Networks used in~\cite{liu2015convolutional} to more task specific architectures such as Wide \& Deep models~\cite{cheng2016wide} and Field-Leveraged Embedding Networks (FLEN)~\cite{chen2019flen}. This approach is in contrast to other approaches such as neural collaborative filtering~\cite{bai2017neural} and K-Nearest Neighbors (KNN) recommenders~\cite{subramaniyaswamy2017adaptive} where we do not attempt to explicitly model the likelihood of the user interacting with a specific item.


\subsection{Social-Aware Recommendation Systems}
When we have social connectivity information for the users we are recommending to, there are many modeling approaches that leverage this information. Methods such as TrustMF~\cite{yang2016social} and Sorec~\cite{ma2008sorec} project user preference vectors into a latent space using matrix factorization approaches. The underlying assumption of these systems is homophily i.e. that users who are more socially connected are more likely to have similar preferences.

Deep-learning based methods have leveraged graph neural networks to learn over the social connectivity structure. Methods such as DiffNet~\cite{wu2019neural} and KCGN~\cite{huang2021knowledge} utilize graph convolutional neural networks whereas methods such as GraphRec~\cite{fan2019graph} and Social Attentional Memory Networks (SAMN)~\cite{chen2019social} employ graph attention mechanisms. Other notable work includes Disentangled Graph Neural Networks (DGNN) which have the capability to model non-heterogeneous relationships and utilize a memory augmented graph network~\cite{xia2023disentangled}. 

In this work we take a different approach to previous work which has used graph neural networks or other custom architectures with separate components to handle the cross-user interactions. We utilize a single transformer decoder with a specifically-designed attention mask to do joint inference over groups of users. With this approach we have a single consistent way to handle both within-user and cross-user interactions.

\section{Problem Statement}
\label{section:problem}
Given historical observational data of users interacting with items on a platform and the users' social connectivity we want to make personalized recommendations of new items that are likely to be interesting.

\section{Methods}
\label{sec:methods}
\subsection{Data}
\label{section:data}
We developed our methodology on a dataset of historical interactions with an educational platform offered by our partner Learning Ally. The data offered was anonymized with each student, school and district being identified only by a unique randomly generated identification number. Furthermore all descriptive data of the students was only available as highly aggregated summaries. In the dataset we have historical records of interactions between students and educational items. For each interaction recorded we have a timestamp, an item ID and an anonymized student ID, an anonymized school ID and a grade level, which is enough metadata to make rough inference of which students are in the same classrooms. This data was collected over two consecutive school years containing over 5 million interactions per each school year totalling over 10 million interactions. These interactions come from a cohort of over 390,000 students. We use the data from the first school year as our training dataset and split the data from our second school year into a validation dataset and a test dataset. This split was done according to the temporal global splitting strategy~\cite{meng2020split}. This was done to model the scenario of deployment as realistically as possible. To partition the data from the second school year into a test set and a validation set we split by student, following the user split strategy~\cite{meng2020split}. This is because if a data split does not contain at least a full academic year then the distributions would not match due to seasonal trends in the data. 

On the item side we have in the order of tens of thousands of items to recommend from.
Overall this dataset is well suited to studying social recommendation algorithms due to the existence of implied social connections through known proximity and also due to the large amount of interaction data on record. Further details on the data can be found in Appendix~\ref{section:app:data}




\subsection{Preprocessing}
\label{section:preprocessing}

In order to get the training data representation, we express the items as tokens. The top $v$ most popular items get a unique and sequential integer as their token, while the rest of the items get assigned to an out-of-vocabulary token. The student interaction history will therefore become a list of such tokens associated with a time point.

The following additional processing steps are taken based on the model type used downstream:
\begin{itemize}
    \item For transformer models: we split the student history into slices based on a context window of length $c$.
    \item For models that process students jointly: we split the sequence associated with each student into segments of length $s$, $s$ < $c$, then compose sequences of length $c$ by joining segments from \textit{multiple} students in the same classroom, taking care to use a separator token.
\end{itemize}

Additional information, including a diagram of our preprocessing steps, are presented in Appendix~\ref{section:app:preprocessing}.

\subsection{Models}
We implement \textbf{KNN} and \textbf{SAMN}\footnote{We used the author's repository \url{https://github.com/chenchongthu/SAMN} as a guideline. We found a discrepancy between this code and the method described in the paper, but it didn't affect final performance.}~\cite{chen2019behavior} as baseline models, a transformer-based model that does inference for each student separately we name \textbf{Individual} as well as a transformer that operates over groups of students we name \textbf{STUDY}. 

\subsubsection{Item-based KNN recommender}
To implement our item-based KNN recommender~\cite{bahadorpour2017determining} we first need to define our items and their corresponding features. To do this we iterate over every sequence in the training dataset and featurize each item by computing a feature vector from the $h$ interactions previously preceding it. Each item in the sequence is represented by a vector of size $v + 1$, one component for each entry in the vocabulary as well as an entry for the out-of-vocabulary token). The $i^{th}$ component of this vector is the number of times the $i^{th}$ item in the vocabulary was interacted with in the users previous $h$ interactions with the system. As $h \ll n$ these feature vectors are very sparse. To make recommendations at inference time, we compute a feature vector from the users $h$ most recent interactions from the users history. We then compute the cosine similarity between the user's current feature vector and each entry in the training dataset. Finally we recommend the user the $k$ distinct items with highest cosine similarity to the user's current feature vector. Due to sparsity most entries in the training dataset will have a cosine similarity of exactly zero with the user's current feature vector. To utilize this fact to make an efficient implementation we precompute an inverse index~\cite{wang2010efficient} for the training data that can be used to retrieve only the feature vectors which have a nonzero value at a specific index. Utilizing this inverse index we only have to compute the cosine similarity for vectors that we know will have a nonzero similarity with our current feature. These are the vectors that have overlapping nonzero entries with the current context. Furthermore, we utilize a library that represents our vectors as sparse vectors, saving both memory and compute when doing arithmetic on these vectors.

\subsubsection{Individual}
Following the click-through rate prediction~\cite{wang2020survey} method of recommendation we take the next-click prediction approach to recommendation, hence we treat making recommendations as a causal sequence-modeling problem. In particular, we borrow a modeling framework from the language modeling literature~\cite{radford2018improving} due to a similar problem setup. Concretely, given a set of students  $s_j \in S$, and a set of historical item interactions $\{i^k_j : \forall j | s_j \in S,  \forall k < \|s_j\|, k \in \mathbb{N} \} $ then we want to learn a propensity function
\begin{center}
    $P({i^k_j }) = f(i^k_j |  i^{k'<k}_j ; \theta)$
\end{center}
where the propensity of an item at point in time the likelihood the student will interact with that item.
To this end we modeled $f$ as causal decoder-only transformer with a next-token prediction objective to maximize the following likelihood of our data $D$
\begin{center}
    $\mathbb{L}(D) = \sum_{s^i_j \in D} \log  f(s^i_j | s^i_{j'<j} ; \theta)$
\end{center}
This is the formulation we used for the model referred to as \textbf{Individual}, since inference is carried out for each individual student separately.

\subsubsection{STUDY}

We motivate our model by observing that for students with little previous interactions to go on, we can rely on data from other students whom we expect to have similar preferences to seed the model to make better predictions. Concretely, we concatenate the interaction sequences of multiple students who are within the same classroom. However when doing this we are no longer able to apply the causal sequence modeling approach to model this problem. This is because some item-interactions for students presented earlier in the sequence could have occurred at a later point in time relative to item-interactions for the students presented later in the sequence. Modeling the data represented in this format using causal sequence modeling would lead to anti-causal data leakage and the model would learn to make recommendations conditioned on information will not be available at inference time. 

Hence we introduce temporally causal masking into our model, a change to our model's forward pass which enables us to use a training process similar to causal sequence modeling while still respecting the causal relationships in our data as shown in Figure~\ref{figure:main}. Conceptually we concatenate the user vectors of students in the same classroom and allow predictions for a particular item to condition on all interactions that happened in the past, both within-user and cross-user. In more detail, if have a subset of users $u^1, u^2, \cdots, u^n$  who are all in the same classroom, with interaction sequences $\boldsymbol{S^1}, \boldsymbol{S^2}, \cdots, \boldsymbol{S^n}$,  and with timestamp vectors $\boldsymbol{T^1},\boldsymbol{T^2}, \cdots \boldsymbol{T^2}$ where $t^i_j$ is the timestamp of the interaction described at $s^i_j$ - and each user vector  $\boldsymbol{S^n}$ and timestamp vector  $\boldsymbol{T^n}$ is terminated with a separator token - we define the concatenated classroom vectors generated by the procedure described in Section~\ref{section:preprocessing} as
\begin{center}
    $\boldsymbol{\hat{S}} = \left( \boldsymbol{S^1} \boldsymbol{S^2} \cdots \boldsymbol{S^n} \right)$
    
    $\boldsymbol{\hat{T}} = \left( \boldsymbol{T^1} \boldsymbol{T^2} \cdots \boldsymbol{T^n} \right)$
\end{center}

And we define the matrix $\boldsymbol{M}$ 
\begin{center}
    $m_{i,j} = \mathbbm{1}_{\hat{t}_i < \hat{t}_j}$
\end{center}
as the temporally causal mask matrix. This matrix is used as the mask in our attention operator instead of the usual causal mask used in decoder-only transformers. Hence our we redefine the attention operator in the decoder-only transformer as follows.
\begin{center}
    $\boldsymbol{A} = \mathrm{Softmax}(\frac{ \boldsymbol{Q K^T}}{\sqrt{d_k}}) \odot \boldsymbol{M}$
    
    $\mathrm{Attention(\boldsymbol{Q}, \boldsymbol{K},  \boldsymbol{V})} =  \boldsymbol{A V}$ 
\end{center}
where  $\boldsymbol{Q}$ is the query matrix,  $\boldsymbol{K}$ is the key matrix and  $\boldsymbol{V}$ is the value matrix. With this modification we can use next-item prediction sequence modeling to train the model without anti-causal information leakage, utilizing a multihead generalization of this attention mechanism~\cite{vaswani2017attention}. We call the model defined by this procedure \textbf{STUDY}. 



\subsection{Experiments}
\label{sec:experiments}
We present results from the Individual and STUDY models, the item-based KNN baseline as well as SAMN~\cite{chen2019social}, a social baseline.  We tune the hyperparameters learning rate on the validation set and report final results on the test set. We took the both the context length $c$ and the segment size $s$ for our transformer models to be 65, enough to the full history of most students in our dataset. Details about further hyperparameters and compute can be found in Appendix~\ref{section:app:experiment}. We use the hits@n scores as our evaluation metric, with hits@n being the percentage of interactions where the actual item interacted with falls within the top $n$ recommendations from the model under evaluation. Since we observe that students tend to repeatedly interact with an item multiple times before completing it, we additionally evaluate our models on the subset of the dataset where the student is interacting with a different item to the item previously interacted with, referred to as \textit{non-continuation} evaluation. We also evaluate on the subset of the dataset where the students are interacting with an item for the first time, referred to as \textit{novel} evaluation. This motivated by the fact that we are interested in the power of our recommendation systems to engage students with new items in order to maximize time spent on the educational platform. Aggregate statistics are computed per student then averaged over students to prevent students with large numbers of interactions from dominating the reported statistics. We also examine the relevant performance of these models on different slices of data, looking at co-factors such as demographic characteristics and school performance. We present the results of this experiment in section~\ref{section:results}.

\subsection{Ablation Experiments}
\textbf{Force Mix}: In our model because we set segment size $s$ equal to context size $c$ we only do joint inference over groups of students when processing a student who does not have enough previous interactions to fill the transformer's context. We experiment with shorter segment size $s = 20 \ll c$ as per the definitions in Section~\ref{section:preprocessing}. Practically this leads the model always sharing its context between students in a classroom when possible, even for students who have enough history to fill the transformer context. We present results for this ablation in Section~\ref{section:ablation_results} 

\textbf{Classroom Grouping}: In STUDY we do joint inference over students in the same classroom. We ablate the importance of using this particular grouping. Concretely, we experiment with grouping students who are in the same district and school year as being in a single group. We also experiment with grouping all students in the dataset into a single group. This results in completely random groups of students being jointly processed together. We present results in Section~\ref{section:ablation_results}.

\textbf{Data Tapering}:We compare the effect of using only a subset of the available data and compare the performance of STUDY and Individual. We compare the use of 25\%, 50\%, 75\% and the entire dataset, with the aim of discerning the effect of using social information on the data efficiency of the system.  We present results in Section~\ref{section:ablation_results}.


\begin{table*}[]
    \centering
    \vspace{0.5em}
   \begin{tabular}{c|c|c|c|c|c}
    \toprule
        Evaluation Subset & $n$ & KNN(\%) & SAMN(\%) & Individual (\%) & STUDY(\%)   \\

        \midrule
\multirow{5}{*}{
          \begin{tabular}{c}
          All
          \end{tabular}
      }
& 1 & $16.67 \pm 0.14$ & $0.32 \pm 0.02$ & $28.06 \pm 0.14$ & $31.86 \pm 0.14$ \\
& 3 & $31.97 \pm 0.17$ & $2.01 \pm 0.05$ & $35.74 \pm 0.16$ & $38.65 \pm 0.14$ \\
& 5 & $37.16 \pm 0.20$ & $3.64 \pm 0.09$ & $38.63 \pm 0.18$ & $41.17 \pm 0.18$ \\
& 10 & $43.17 \pm 0.20$ & $6.87 \pm 0.10$ & $42.56 \pm 0.20$ & $44.85 \pm 0.18$ \\
& 20 & $48.02 \pm 0.20$ & $11.56 \pm 0.15$ & $46.70 \pm 0.20$ & $48.90 \pm 0.18$ \\
\midrule

\multirow{5}{*}{
          \begin{tabular}{c}
          Non-continuation
          \end{tabular}
      }
& 1 & $5.15 \pm 0.08$ & $0.33 \pm 0.02$ & $2.05 \pm 0.04$ & $3.75 \pm 0.07$ \\
& 3 & $9.35 \pm 0.08$ & $1.95 \pm 0.04$ & $10.38 \pm 0.11$ & $13.76 \pm 0.11$ \\
& 5 & $11.47 \pm 0.13$ & $3.56 \pm 0.07$ & $14.35 \pm 0.10$ & $17.66 \pm 0.11$ \\
& 10 & $14.93 \pm 0.10$ & $6.68 \pm 0.09$ & $19.96 \pm 0.13$ & $23.05 \pm 0.13$ \\
& 20 & $19.42 \pm 0.15$ & $11.29 \pm 0.15$ & $26.27 \pm 0.14$ & $29.50 \pm 0.16$ \\
\midrule

\multirow{5}{*}{
          \begin{tabular}{c}
          Novel
          \end{tabular}
      }
& 1 & $0.58 \pm 0.03$ & $0.32 \pm 0.02$ & $1.06 \pm 0.04$ & $1.86 \pm 0.06$ \\
& 3 & $2.21 \pm 0.06$ & $1.87 \pm 0.05$ & $5.03 \pm 0.09$ & $6.60 \pm 0.10$ \\
& 5 & $3.73 \pm 0.05$ & $3.45 \pm 0.06$ & $8.02 \pm 0.12$ & $9.77 \pm 0.13$ \\
& 10 & $6.68 \pm 0.08$ & $6.47 \pm 0.12$ & $13.14 \pm 0.12$ & $15.06 \pm 0.15$ \\
& 20 & $11.12 \pm 0.10$ & $10.99 \pm 0.11$ & $19.56 \pm 0.14$ & $22.01 \pm 0.16$ \\
\bottomrule

\end{tabular}
    \caption{Hits@n percentage metrics for the different recommendations models evaluated on the historical data in the test split. We report overall test scores over three subsets of the test split: \textit{all}, \textit{non-continuation} and \textit{novel}. We see both transformer decoder approaches significantly outperforming KNN and SAMN with STUDY having the best performance. Uncertainties are $95\%$ confidence intervals computed over 50 bootstraps.}
\label{tab:main_results}

\end{table*}


\begin{figure}[]
    \centering
    \begin{subfigure}[]{0.4\linewidth}
        \includegraphics[width=\linewidth]{figures/engagement.pdf}
        \caption{}
    \end{subfigure}
    \begin{subfigure}[]{0.4\linewidth}    
        \includegraphics[width=\linewidth]{figures/force_mix.pdf}
    \caption{}
    \end{subfigure}
    \caption{These figures show the performance of the presented models broken down by student engagement, accompanied by a histogram of student engagement in the lower chart. In (a) we present the four models KNN, SAMN, Individual and STUDY. We see the two transformer based approaches outperform KNN and SAMN. We also see that the STUDY model significantly outperforms the Individual model for students with low engagement up to 35 interactions. In (b) we present a comparison of the Individual against the Force Mix ablation. We see the Force Mix ablation only outperforms Individual on students with engagement of up to 17, with matched performance onwards. Uncertainties shown are $95\%$ confidence intervals computed over 50 bootstraps.}
    \label{fig:engagement}
\end{figure}


\begin{figure}[]
    \centering
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\linewidth]{figures/socio_economic.pdf}
        \caption{}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\linewidth]{figures/reading_score.pdf}
        \caption{}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\linewidth]{figures/metro_code.pdf}
        \caption{}
    \end{subfigure}
    \caption{In this figure we show the slicing of our models performance by (a) socio-economic indicator, (b) by classroom reading score and (c) Metro code which describes schools as being Urban, Suburban, Rural or Town. We show histograms of the sliced variables in the lower figures. We see the relative order of performance Temporally Causal $>$ Individual $\gg$ KNN $\gg$ SAMN is maintained across all slices. Uncertainties shown are $95\%$ confidence intervals. In (a) and (c) uncertainties are shown as error bars but are very small.}
    \label{fig:slices}
\end{figure}


\begin{figure}[]
  \centering
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=\linewidth]{figures/classroom_ablation.pdf}
        \caption{}
        \label{fig:classroom_ablation}
    \end{subfigure}
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=\linewidth]{figures/data_tapering.pdf}
        \caption{}
        \label{fig:data_ablation}
    \end{subfigure}
        \caption{In Figure~(a) we compare the results of grouping the students for STUDY by classroom, grouping by the intersection of district and school year, grouping randomly as well doing individual inference. We observe that grouping by classroom performs best, that grouping by district $\times$ school year performs slightly worse, and that random grouping is on par with individual inference.
        In Figure~(b) we show the effect of training with subsets of the training data of various sizes on Individual and STUDY. We see that STUDY outperforms Individual at all subset sizes. We also note the drop in performance when increasing the dataset size from 50\% to 75\% across both models. Uncertainties shown are $95\%$ confidence intervals computed over 50 bootstraps and are obscured by datapoint markers when small.  }
\end{figure}

\section{Results and Analysis}
\label{section:results}
Table~\ref{tab:main_results} shows the performance of the models STUDY, Individual, KNN and SAMN on the test split and we observe both transformer models, Individual and STUDY largely outperform KNN and SAMN, with the STUDY model outperforming the Individual model. We see that the social model SAMN which is from the a collaborative filtering family of models, fails to pick up on the sequential patterns in the dataset, such as users revisiting the exact same item or similar items, this is exhibited by SAMN having similar performance in the evaluation subsets {\it all}, {\it non-continuation} and {\it novel}. The performance differences are most pronounced when evaluated on the entire test set as seen in the \textit{all} section of the table, but also holds up when evaluated across the more difficult \textit{non-continuation} and \textit{novel} test subsets. Crucially, with the STUDY model outperforming the individual model we can see that leveraging the social hierarchy of our users to do joint predictions leads to improved recommendations.

In Figure~\ref{fig:slices} we see the relative performance of the models under examination to be constant, with STUDY outperforming Individual which in turn outperforms KNN and SAMN trailed behind with almost 0 hits@1, we attribute this due to SAMN's non-sequential nature. This ordering is fixed when slicing by demographic variables such as metro-code (which describes schools as being in urban, suburban, rural or town areas), school socio-economic indicators which indicate the level of wealth of the area the in the vicinity of a school. We also observe the same when slicing by academic variables such as classroom reading scores. In Figure~\ref{fig:engagement} we slice model performance by student engagement, which we measure by the number of interactions the student has on record. Here we see similar relative performance order for students with less than 35 or so total interactions, but for students with more engagement we see convergence between the performance of STUDY and Individual. This is discussed in more detail in Section~\ref{section:ablation_results}.

\subsection{Ablations Results}
\label{section:ablation_results}

\textbf{Force Mix}: In Figure~\ref{fig:engagement} we can compare the performance of the STUDY model to the individual model and we can observe it significantly outperforms the individual model on students with up to 35 previous interactions. Compared to the model from the Force Mix ablation only outperforms Individual on students who have up to about 17 interactions on the platform. Given that our segment length for the Force Mix model is 20, it is at students with 20 previous where Force Mix starts to forgo on available history for the student at hand in favor of conditioning on data from other peer students. From here we can conclude that conditioning on peer student history is beneficial if and only if it is additional to conditioning on all available history for a student, but not if it comes at the cost of conditioning on less history than available for the particular student.

\textbf{Classroom Grouping}: In Figure~\ref{fig:classroom_ablation} we can compare the performance of our model that uses classrooms to group students for joint inference compared to a model that uses intersection of district and school year to group students, to a model that uses a single group as well as to a model that does inference for each student individually. We can see that using classrooms for grouping results in the best performance, that using the intersection of district and school year for grouping performs slightly worse, and that putting all students in the same group performs similar to individual processing. From here we can conclude that using groups of users whom we expect to have correlated interests is necessary for the performance of our model and using poorly designed groups can harm model performance.

\textbf{Data Tapering}: In Figure~\ref{fig:data_ablation} we see that STUDY outperforms the Individual recommender across all data subsets used to train the models, confirming the benefit of adopting social recommender systems such as STUDY even when in a data-constrained environment. We also note that both models witness a performance drop when the amount of data used increases from 50\% to 75\%, suggesting that not all additional data is beneficial. We leave a deeper interpretation of this phenomenon to future work.   

\section{Conclusion}

In this method we present STUDY, a socially aware recommendation system that leverages cross-user information at inference time and we demonstrate its applicability on the practical problem of book recommendation for children inside a classroom. This is an important problem, as engagement with reading materials from an early age can have a positive impact on language acquisition, communication skills, social skills and literacy skills to name a few.

Our novel method uses attention masks that are causal with respect to interaction timestamps and is able to process both within-user and across user interactions using a single forward pass through a modified transformer decoder network. In doing so, we keep away from complex architectures and avoid the need for graph neural networks which are notoriously difficult to train. We further compare with a number of baselines, both sequential and non-sequential, and social and non-social. We show that our method outperforms both sequential and social methods, in a variety of scenarios as demonstrated through our ablation studies.

\textbf{Limitations}: Our evaluations were limited to offline evaluations on historical data, which although inline with much of the literature, these evaluations cannot account for the utility of recommended items that the user has never interacted with in the past, but would have actually enjoyed. Furthermore, our method is limited to structures where all the known relationships between users are homogeneous. In future work we wish to explore extending this method to social networks with richer heterogeneous relationships between users.

\section{Acknowledgements}
We would like to acknowledge our partners Jeff Ho, Akshat Shah, Erin Walker, and Tyler Bastian at Learning Ally for partnering with us on data and graciously providing us with educational domain subject matter expertise. We would also like to acknowledge our colleagues at Google: Marc Repnyek, Aki Estrella, Fernando Diaz, Scott Sanner, Emily Salkey and Lev Proleev for the fruitful discussions, technical support and collaboration on this project.



\FloatBarrier
\bibliographystyle{unsrt}
\bibliography{bib}

\clearpage

\appendix
\section*{{\huge Appendix}}
\section{Data}
\FloatBarrier
Here we provide some descriptive statistics about the data this research was conducted on.  The data  was collected over two school years by our data partner Learning Ally. To protect the privacy of individuals and entities all personally identifiable information was removed from the dataset by Learning Ally before we had access to the data. Furthermore much of the available metadata was redacted or had its granularity reduced so individuals and entities cannot be identified. All identification numbers in the dataset supplied were randomly generated and are not traceable back to individual students by us. Table~\ref{table:data_overview} shows descriptive statistics about the platform interactions recorded as well as metadata describing the students under observation.


\label{section:app:data}
\newcommand\pageSplitL{0.5}
\newcommand\pageSplitR{0.5}   
\newcommand\captionwidthr{0.7}   
\begin{table}[h]
\centering
 \begin{subtable}[b]{\pageSplitL\linewidth}\centering
   \captionsetup{width=\captionwidthr\linewidth}
    {\begin{tabular}{l r}
      \toprule
      \multicolumn{1}{r}{\bf Grade Level} & \multicolumn{1}{c}{ \bf Number of Students} \\
      \midrule
      Grade 1 & 1726 \\
      Grade 2 & 6386 \\
      Grade 3 & 16668 \\
      Grade 4 & 28762 \\
      Grade 5 & 41070 \\
      Grade 6 & 49805 \\
      Grade 7 & 59836 \\
      Grade 8 & 57413 \\
      Grade 9 & 51217 \\
      Grade 10 & 31611 \\
      Grade 11 & 18353 \\
      Grade 12 & 14717 \\
      Other & 137671 \\
      \bottomrule
\end{tabular}
\caption{A breakdown of the students in the dataset by grade level.}
\vspace{4.47em}
  \begin{tabular}{l r}
      \toprule
      \multicolumn{1}{r}{\bf Wealth Indicator} & \multicolumn{1}{c}{ \bf Number of Students} \\
      \midrule
      A & 120281 \\
      B & 91325 \\
      C & 74855 \\
      D & 61685 \\
      E & 39083 \\
      Unknown & 12108 \\
      \bottomrule
\end{tabular}
\caption{A breakdown of the students in the dataset by the wealth indicator associated with their school (A is highest).}}
\end{subtable}%
\begin{subtable}[b]{\pageSplitR\linewidth}\centering{
\captionsetup{width=\captionwidthr\linewidth}
  \centering
  \begin{tabular}{l r}
      \toprule
      \multicolumn{1}{r}{\bf Percentile} & \multicolumn{1}{c}{ \bf Time Spent on Platform} \\
      \midrule
      5$^{th}$ & 3m \\
      25$^{th}$ & 35m \\
      50$^{th}$ & 2h 35m \\
      75$^{th}$ & 8h 12m \\
      95$^{th}$ & 33h 33m \\
      \bottomrule
\end{tabular}
\caption{Percentiles of the amount of interaction time logged by students in the first data collection year.}
  \centering 
  \begin{tabular}{l r}
      \toprule
      \multicolumn{1}{r}{\bf Percentile} & \multicolumn{1}{c}{ \bf Time Spent on Platform} \\
      \midrule
      5$^{th}$ & 2m \\
      25$^{inth}$ & 29m \\
      50$^{th}$ & 2h 14m \\
      75$^{th}$ & 7h 34m \\
      95$^{th}$ & 35h 25m \\
      \bottomrule
\end{tabular}
\caption{Percentiles of the amount of interaction time logged by students in the second data collection year.}
\begin{tabular}{c c}
         \toprule
         \bf Percentile & \bf Interaction Count  \\
         \midrule
         $5^{th}$ & 1 \\
         $25^{th}$ & 3 \\
         $50^{th}$ & 10 \\
         $75^{th}$ & 29 \\
         $95^{th}$ & 105 \\
        \bottomrule
    \end{tabular}
        \caption{Percentiles of the total number of interactions logged per student in the dataset after aggregating over both school years.}}
\end{subtable}
\caption{This table shows some descriptive statistics relating to the students in the dataset as well as the amount data logged for each student}
\label{table:data_overview}
\end{table}


\begin{table}
    \centering
    \begin{tabular}{p{3.5cm} r r r r}
         \toprule
          && \multicolumn{1}{r}{\bf Train} & \multicolumn{1}{c}{\bf Validation} & \multicolumn{1}{r}{\bf Test}  \\
         \midrule
         Number of Interactions && $5{,}179{,}466$ & $2{,}752{,}671$  & $2{,}747{,}699$ \\
         Number of Students && $237{,}253$& $126{,}049$ & $126{,}050$ \\  
         Number of Classrooms && $40{,}522$ & $30{,}243$ & $30{,}400$ \\
         Number of Districts && $2{,}510$& $2{,}378$&  $2{,}387$\\

        \bottomrule
    \end{tabular}
    \newline
    \newline
    \caption{This table provides descriptive statistics with regards to the number of interactions we have on record for each student. Students, classrooms and districts whose interactions appear in the training set might also have interactions collected at a later date that appear in the validation and test splits as the data split was partially temporal and not purely user based}
    \label{table:data_split}
\end{table}

To generate train, validation and test splits the following procedure was followed. The data from the first school year was taken as our training dataset and we split the data from the second school year into a validation and test datasets.  This first split was done according to the temporal global splitting strategy~\cite{meng2020split}. This was done to model the scenario of deployment as realistically as possible. To partition the data from the second school year into a test set and a validation set we split by student, with all interactions recorded for a particular student collected in the second school year are either all the testing dataset or all the validation dataset. This second split followed the user split strategy~\cite{meng2020split} because if a data split does not contain at least a full academic year then the distributions would not match due to seasonal trends in the data. Table~\ref{table:data_split} shows some key statistics for the data splits

\section{Preprocessing}
 We apply the following preprocessing steps to our data before using it to train our models. 
First, we represent the items under recommendation with tokens. The tokens are sequential integers for the $v$ most popular items. We take the vocabulary size $v$ to be 2000. We then assign all the remainder of the items to a single unique token used to represent out-of-vocabulary items. 



\label{section:app:preprocessing}
\newcommand\proprocessingA{89.0}
\newcommand\proprocessingB{170.69}
\newcommand\proprocessingScale{0.006\linewidth}
\begin{figure}[h]
    \centering
    \begin{subfigure}[]{0.8\linewidth}
        \centering
        \includegraphics[width=0.534\linewidth]{figures/appendix/preprocessing_a.pdf}
        \caption{For \textit{Individual} sequences relating to different students are split into contexts of length $c$. Each context is fed into the transformer as a separate datapoint.}
    \end{subfigure}
    
    \vspace{3em}
    \begin{subfigure}[]{0.8\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/appendix/preprocessing_b.pdf}
        \caption{For \textit{STUDY} we split sequences relating to students into segments of length $s$, $s \leq c$. We then sample multiple chunks from different students in the same classroom. The sampled segments are then concatenated with separator tokens (shown in gray) in between them to form datapoints of at most length $c$. }
    \end{subfigure}
    \vspace{2em}
    \caption{This figure details the preprocessing pipelines used for the two transformer models, with the pipeline for \textit{Individual} shown in (a) and the pipeline for \textit{STUDY} shown in (b)}
    \label{fig:preprocessing}
\end{figure}

Additional preprocessing is applied for Individual and STUDY. For the Individual model we set a context window length $c$ and split students with interaction histories longer than $c$ items into separate data-points of at most length $c$. We took context length $c=65$ for the transformer models. This is necessary as although the vast majority of sequences in each data split (over 92\%) are under 65 entries in length, there exists a long tail of sequences with very long length. 

For STUDY slightly different processing is required. We first split the sequence associated with each student into \textit{segments} of at most length $s$, $s\leq c$. Then we compose data-points of at most length $c$ by concatenating together multiple \textit{segments} from multiple students in the same classroom separated with separator tokens. To compose a single data-point we sample multiple segments from students in the same classroom, while satisfying the constraints that overall length of each data-point is at most $c$ and that we do not sample more than one segment from a single student. In our final model we took $s=c=65$ Figure~\ref{fig:preprocessing} shows a diagram explaining these procedures.
\FloatBarrier
\section{Experimental Details}
\label{section:app:experiment}
In the following section we detail the choices of hyperparameters and the computational resources needed.
For the KNN recommender we took K to be equal to 2. There were no further hyperparameters for the KNN recommender. The KNN recommender system had no training requirements, only preprocessing and inference, which we were able to run on the entire test split on a single machine with no GPU or TPU accelerators within a few hours.
For STUDY, Individual and SAMN we used the Adam Optimizer with the following learning rate schedule
\begin{equation*}
    \alpha (s) = \begin{cases}
        \alpha_p  * s / W & 0 < s \leq W \\
        \frac{\alpha_p}{\sqrt{s - W}} & s > W
   \end{cases}
\end{equation*}
\vfill
\begin{table}[h]
\centering
 \begin{subtable}[t]{\pageSplitL\linewidth}\centering
   \captionsetup{width=\captionwidthr\linewidth}
    \begin{tabular}{l r}
      \toprule
      \multicolumn{1}{r}{\bf Individual} & \\
      \midrule
      Peak Learning Rate $\alpha_p$  & 0.1024\\
      Warm up steps $W$ & 1000 \\
      Total steps & 3500 \\
      Batch Size & 131,072 \\
      Number of TPUs & 32 \\
      Run time & $\sim$12 hours \\
      \bottomrule
\end{tabular}

\vspace{4.47em}
\begin{tabular}{l r}
      \toprule
      \multicolumn{1}{r}{\bf STUDY} &  \\
      \midrule
      Peak Learning Rate $\alpha_p$  & 0.1024\\
    Warm up steps $W$ & 1000 \\
      Total steps & 3500 \\
      Batch Size & 131,072 \\
      Number of TPUs & 32 \\
      Run time & $\sim$12 hours \\
      \bottomrule
\end{tabular}
\end{subtable}%
\begin{subtable}[t]{\pageSplitR\linewidth}\centering
\captionsetup{width=\captionwidthr\linewidth}
  \centering
     \begin{tabular}{l r}
      \toprule
      \multicolumn{1}{r}{\bf SAMN} & \\
      \midrule
      Peak Learning Rate $\alpha_p$  & 0.0128\\
      Warm up steps $W$ & 350 \\
      Total steps & 3500 \\
      Batch Size & 524,288 \\
      Number of TPUs & 32 \\
      Run time & $\sim$3 hours \\
      \bottomrule
\end{tabular}
\end{subtable}
\vspace{3em}
\caption{This table shows hyperparameter values as well as computation resources for STUDY, Individual and SAMN.}
\label{table:hyperparams}
\end{table}
\clearpage



where $\alpha(s)$ is the learning rate at $s^{th}$ step, $\alpha_p$ is the peak learning rate and $W$ is the number of warm up steps. The $\alpha_p$ and batch size were tuned for each model individually. We used Google Cloud TPUs with the number of TPUs used shown along with the hyperparameter values in Table~\ref{table:hyperparams} We note that we were able to obtain good results with our models using smaller batch sizes but opted for larger batch sizes for faster development iteration speed.

\end{document}